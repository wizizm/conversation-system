#!/usr/bin/env python3
"""
Enhanced MCP Server with SSE Transport
Compatible with Cursor and other MCP clients supporting SSE
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional

import httpx
import uvicorn
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === ENHANCED API CLIENT ===

class EnhancedConversationAPI:
    """å¢å¼ºçš„APIå®¢æˆ·ç«¯ï¼Œæ”¯æŒæ™ºèƒ½å‹ç¼©å’Œé€‚åº”æ€§ä¸Šä¸‹æ–‡"""
    
    def __init__(self, base_url: str = "http://conversation_app:9000"):
        self.base_url = base_url.rstrip('/')
        # é…ç½®æ›´ç¨³å®šçš„HTTPå®¢æˆ·ç«¯
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0, connect=10.0),
            limits=httpx.Limits(max_connections=20, max_keepalive_connections=5),
            transport=httpx.AsyncHTTPTransport(retries=3)
        )
        logger.info(f"ğŸ”— Enhanced API client initialized: {base_url}")
    
    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥API"""
        try:
            response = await self.client.get(f"{self.base_url}/health")
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Health check failed: {e}")
            raise
    
    async def record_conversation(self, user_msg: str, assistant_msg: str, 
                                topics: List[str] = None, keywords: List[str] = None) -> Dict[str, Any]:
        """è®°å½•å¢å¼ºå¯¹è¯"""
        try:
            payload = {
                "role": "user",
                "content": user_msg,
                "topics": topics or [],
                "keywords": keywords or []
            }
            
            # Save user message
            user_response = await self.client.post(f"{self.base_url}/messages", json=payload)
            user_response.raise_for_status()
            
            # Save assistant message
            payload["role"] = "assistant"
            payload["content"] = assistant_msg
            
            assistant_response = await self.client.post(f"{self.base_url}/messages", json=payload)
            assistant_response.raise_for_status()
            
            return {
                "user_message_id": user_response.json().get("message_id"),
                "assistant_message_id": assistant_response.json().get("message_id"),
                "compression_ratio": assistant_response.json().get("compression_ratio", 0),
                "bytes_saved": assistant_response.json().get("bytes_saved", 0),
                "status": "saved"
            }
        except httpx.TimeoutException as e:
            logger.error(f"API timeout error: {e}")
            raise Exception(f"API request timeout: {e}")
        except httpx.ConnectError as e:
            logger.error(f"API connection error: {e}")
            raise Exception(f"Cannot connect to API service: {e}")
        except Exception as e:
            logger.error(f"Error recording enhanced conversation: {e}")
            raise

    async def get_analytics(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºåˆ†ææ•°æ®"""
        try:
            response = await self.client.get(f"{self.base_url}/analytics")
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error getting analytics: {e}")
            raise

    async def get_context(self, limit: int = 5, detail_level: str = "medium", format_type: str = "narrative") -> Dict[str, Any]:
        """è·å–é€‚åº”æ€§ä¸Šä¸‹æ–‡"""
        try:
            payload = {
                "limit": limit,
                "detail_level": detail_level,
                "format_type": format_type
            }
            response = await self.client.post(f"{self.base_url}/context", json=payload)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error getting context: {e}")
            raise

    async def search_conversations(self, query_terms: List[str], limit: int = 10, search_scope: str = "all") -> List[Dict[str, Any]]:
        """æœç´¢ä¼šè¯å¢å¼ºç‰ˆ"""
        try:
            payload = {
                "query_terms": query_terms,
                "limit": limit,
                "search_scope": search_scope
            }
            response = await self.client.post(f"{self.base_url}/search", json=payload)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error searching conversations: {e}")
            raise

    async def save_message(self, role: str, content: str, topics: List[str] = None, keywords: List[str] = None) -> Dict[str, Any]:
        """ä¿å­˜æ¶ˆæ¯å¢å¼ºç‰ˆ"""
        try:
            payload = {
                "role": role,
                "content": content,
                "topics": topics or [],
                "keywords": keywords or []
            }
            response = await self.client.post(f"{self.base_url}/messages", json=payload)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error saving message: {e}")
            raise

    async def analyze_compression(self, text: str) -> Dict[str, Any]:
        """å‹ç¼©åˆ†æ"""
        try:
            payload = {"text": text}
            response = await self.client.post(f"{self.base_url}/analyze-compression", json=payload)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Error analyzing compression: {e}")
            raise

    async def save_insight(self, insight_type: str, content: str, summary: str = "", 
                          source_messages: List[str] = None, relevance_score: float = 0.8,
                          business_area: str = "", impact_level: str = "medium",
                          actionable_items: List[str] = None) -> str:
        """ä¿å­˜æ´å¯Ÿå¢å¼ºç‰ˆ"""
        try:
            payload = {
                "insight_type": insight_type,
                "content": content,
                "summary": summary,
                "source_messages": source_messages or [],
                "relevance_score": relevance_score,
                "business_area": business_area,
                "impact_level": impact_level,
                "actionable_items": actionable_items or []
            }
            response = await self.client.post(f"{self.base_url}/insights", json=payload)
            response.raise_for_status()
            result = response.json()
            return result.get("insight_id", "")
        except Exception as e:
            logger.error(f"Error saving insight: {e}")
            raise

# Initialize enhanced API client
api = EnhancedConversationAPI(
    base_url=os.getenv("CONVERSATION_API_URL", "http://conversation_app:9000")
)

# === MCP TOOL IMPLEMENTATIONS ===

async def record_current_conversation(user_message: str, assistant_message: str, 
                                   topics: Optional[List[str]] = None, 
                                   keywords: Optional[List[str]] = None) -> str:
    """è®°å½•å½“å‰å¯¹è¯äº¤æ¢ï¼Œæ”¯æŒæ™ºèƒ½å‹ç¼©"""
    try:
        result = await api.record_conversation(
            user_msg=user_message,
            assistant_msg=assistant_message,
            topics=topics or [],
            keywords=keywords or []
        )
        
        compression_ratio = result.get('compression_ratio', 0)
        bytes_saved = result.get('bytes_saved', 0)
        
        response = f"âœ… Enhanced conversation recorded successfully!\n\n"
        response += f"ğŸ“Š Compression Statistics:\n"
        response += f"  â€¢ Compression Ratio: {compression_ratio:.1%}\n"
        response += f"  â€¢ Bytes Saved: {bytes_saved:,}\n"
        response += f"  â€¢ Smart Features: âœ… Adaptive Context, âœ… Multi-layer Summary\n"
        
        if result.get('technical_terms'):
            response += f"  â€¢ Technical Terms Extracted: {len(result['technical_terms'])}\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error recording conversation: {e}")
        return f"âŒ Failed to record conversation: {str(e)}"

async def get_analytics_tool() -> str:
    """è·å–ç³»ç»Ÿåˆ†ææ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯"""
    try:
        analytics = await api.get_analytics()
        
        total_messages = analytics.get('total_messages', 0)
        compression_stats = analytics.get('compression_stats', {})
        tech_terms = analytics.get('technical_terms', [])
        
        response = f"ğŸ“Š System Analytics Report\n\n"
        response += f"ğŸ“ˆ Total Messages: {total_messages:,}\n"
        
        if compression_stats:
            total_saved = compression_stats.get('total_bytes_saved', 0)
            avg_ratio = compression_stats.get('average_compression_ratio', 1.0)
            response += f"ğŸ’¾ Total Bytes Saved: {total_saved:,}\n"
            response += f"ğŸ“‰ Average Compression: {(1-avg_ratio)*100:.1f}%\n"
        
        if tech_terms:
            response += f"ğŸ”§ Technical Terms Indexed: {len(tech_terms)}\n"
            response += f"   Top terms: {', '.join(tech_terms[:5])}\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error getting analytics: {e}")
        return f"âŒ Failed to get analytics: {str(e)}"

async def get_context_tool(limit: int = 5, detail_level: str = "medium", format_type: str = "narrative") -> str:
    """è·å–é€‚åº”æ€§ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    try:
        context = await api.get_context(limit=limit, detail_level=detail_level, format_type=format_type)
        
        context_text = context.get('context', '')
        compression_stats = context.get('compression_stats', {})
        
        response = f"ğŸ” Context Retrieved (Detail: {detail_level})\n\n"
        response += f"ğŸ“„ Context Length: {len(context_text)} characters\n"
        
        if compression_stats.get('detail_level_used'):
            response += f"ğŸ¯ Detail Level Used: {compression_stats['detail_level_used']}\n"
        
        response += f"\nğŸ“ Context:\n{context_text[:500]}..."
        if len(context_text) > 500:
            response += f"\n\n(Showing first 500 characters of {len(context_text)} total)"
        
        return response
        
    except Exception as e:
        logger.error(f"Error getting context: {e}")
        return f"âŒ Failed to get context: {str(e)}"

async def search_conversations_tool(query_terms: List[str], limit: int = 10, search_scope: str = "all") -> str:
    """æœç´¢ä¼šè¯å†…å®¹"""
    try:
        results = await api.search_conversations(query_terms=query_terms, limit=limit, search_scope=search_scope)
        
        response = f"ğŸ” Search Results (Scope: {search_scope})\n\n"
        response += f"ğŸ“Š Found {len(results)} conversations\n\n"
        
        for i, result in enumerate(results[:5], 1):  # Show top 5 results
            response += f"{i}. "
            if 'summary' in result:
                response += f"{result['summary'][:100]}...\n"
            elif 'content' in result:
                response += f"{result['content'][:100]}...\n"
            
            if 'technical_terms' in result and result['technical_terms']:
                response += f"   ğŸ”§ Tech terms: {', '.join(result['technical_terms'][:3])}\n"
            
            if 'compression_ratio' in result and result['compression_ratio'] < 1.0:
                savings = int((1 - result['compression_ratio']) * 100)
                response += f"   ğŸ’¾ Compression: {savings}% savings\n"
            
            response += "\n"
        
        if len(results) > 5:
            response += f"... and {len(results) - 5} more results\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error searching conversations: {e}")
        return f"âŒ Failed to search conversations: {str(e)}"

async def save_message_tool(role: str, content: str, topics: Optional[List[str]] = None, keywords: Optional[List[str]] = None) -> str:
    """ä¿å­˜æ¶ˆæ¯åˆ°ç³»ç»Ÿ"""
    try:
        result = await api.save_message(role=role, content=content, topics=topics or [], keywords=keywords or [])
        
        message_id = result.get("message_id", "")
        compression_ratio = result.get("compression_ratio", 1.0)
        content_length = result.get("content_length", len(content))
        tech_terms_count = result.get("technical_terms_extracted", 0)
        
        response = f"âœ… Message saved successfully!\n\n"
        response += f"ğŸ†” Message ID: {message_id}\n"
        response += f"ğŸ“ Content Length: {content_length} characters\n"
        
        if compression_ratio < 1.0:
            savings = int((1 - compression_ratio) * 100)
            response += f"ğŸ’¾ Compression: {compression_ratio:.2f} ratio ({savings}% savings)\n"
        
        if tech_terms_count > 0:
            response += f"ğŸ”§ Technical terms extracted: {tech_terms_count}\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error saving message: {e}")
        return f"âŒ Failed to save message: {str(e)}"

async def analyze_compression_tool(text: str) -> str:
    """åˆ†ææ–‡æœ¬çš„å‹ç¼©æ½œåŠ›"""
    try:
        analysis = await api.analyze_compression(text)
        
        original_length = analysis.get('original_length', len(text))
        compression_ratio = analysis.get('compression_ratio', 1.0)
        bytes_saved = analysis.get('bytes_saved', 0)
        short_summary = analysis.get('short_summary', '')
        tech_terms = analysis.get('technical_terms', [])
        
        response = f"ğŸ”¬ Compression Analysis Results\n\n"
        response += f"ğŸ“ Original Length: {original_length} characters\n"
        
        if compression_ratio < 1.0:
            savings_pct = int((1 - compression_ratio) * 100)
            response += f"ï¿½ï¿½ Compression Ratio: {compression_ratio:.2f} ({savings_pct}% savings)\n"
            response += f"ğŸ“‰ Bytes Saved: {bytes_saved:,}\n"
        
        if short_summary:
            response += f"\nğŸ“‹ Generated Summary:\n{short_summary}\n"
        
        if tech_terms:
            response += f"\nğŸ”§ Technical Terms Found ({len(tech_terms)}):\n"
            response += f"   {', '.join(tech_terms[:8])}\n"
            if len(tech_terms) > 8:
                response += f"   ... and {len(tech_terms) - 8} more\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error analyzing compression: {e}")
        return f"âŒ Failed to analyze compression: {str(e)}"

async def save_insight_tool(insight_type: str, content: str, summary: str = "", 
                           source_messages: Optional[List[str]] = None, relevance_score: float = 0.8,
                           business_area: str = "", impact_level: str = "medium",
                           actionable_items: Optional[List[str]] = None) -> str:
    """ä¿å­˜æ´å¯Ÿåˆ°ç³»ç»Ÿ"""
    try:
        insight_id = await api.save_insight(
            insight_type=insight_type,
            content=content,
            summary=summary,
            source_messages=source_messages or [],
            relevance_score=relevance_score,
            business_area=business_area,
            impact_level=impact_level,
            actionable_items=actionable_items or []
        )
        
        response = f"âœ… Insight saved successfully!\n\n"
        response += f"ğŸ†” Insight ID: {insight_id}\n"
        response += f"ğŸ“Š Type: {insight_type}\n"
        response += f"â­ Relevance Score: {relevance_score:.1f}\n"
        response += f"ğŸ¢ Business Area: {business_area}\n"
        response += f"ğŸ“ˆ Impact Level: {impact_level}\n"
        
        if actionable_items:
            response += f"\nğŸ¯ Actionable Items ({len(actionable_items)}):\n"
            for item in actionable_items[:3]:
                response += f"  â€¢ {item}\n"
            if len(actionable_items) > 3:
                response += f"  ... and {len(actionable_items) - 3} more items\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error saving insight: {e}")
        return f"âŒ Failed to save insight: {str(e)}"

# === MCP TOOL REGISTRY ===

MCP_TOOLS = {
    "record_current_conversation_tool": {
        "function": record_current_conversation,
        "description": "Record the current conversation exchange with smart compression and adaptive context",
        "inputSchema": {
            "type": "object",
            "properties": {
                "user_message": {"type": "string", "description": "The user's message"},
                "assistant_message": {"type": "string", "description": "The assistant's response message"},
                "topics": {"type": "array", "items": {"type": "string"}, "description": "Related topics (optional)"},
                "keywords": {"type": "array", "items": {"type": "string"}, "description": "Key terms (optional)"}
            },
            "required": ["user_message", "assistant_message"]
        }
    },
    "get_analytics_tool": {
        "function": get_analytics_tool,
        "description": "Get system analytics including message counts, compression statistics, and technical term analysis",
        "inputSchema": {
            "type": "object",
            "properties": {},
            "required": []
        }
    },
    "get_context_tool": {
        "function": get_context_tool,
        "description": "Retrieve adaptive context information with configurable detail levels",
        "inputSchema": {
            "type": "object",
            "properties": {
                "limit": {"type": "integer", "description": "Number of context items to retrieve", "default": 5},
                "detail_level": {"type": "string", "enum": ["short", "medium", "full", "adaptive"], "description": "Level of detail for context", "default": "medium"},
                "format_type": {"type": "string", "enum": ["narrative", "bullet", "structured"], "description": "Format type for context", "default": "narrative"}
            },
            "required": []
        }
    },
    "search_conversations_tool": {
        "function": search_conversations_tool,
        "description": "Search conversations with enhanced scope options and technical term matching",
        "inputSchema": {
            "type": "object",
            "properties": {
                "query_terms": {"type": "array", "items": {"type": "string"}, "description": "Search terms to find"},
                "limit": {"type": "integer", "description": "Maximum number of results", "default": 10},
                "search_scope": {"type": "string", "enum": ["all", "technical", "topics", "summaries"], "description": "Search scope", "default": "all"}
            },
            "required": ["query_terms"]
        }
    },
    "save_message_tool": {
        "function": save_message_tool,
        "description": "Save a message to the system with compression and technical term extraction",
        "inputSchema": {
            "type": "object",
            "properties": {
                "role": {"type": "string", "enum": ["user", "assistant", "system"], "description": "Message role"},
                "content": {"type": "string", "description": "Message content"},
                "topics": {"type": "array", "items": {"type": "string"}, "description": "Related topics (optional)"},
                "keywords": {"type": "array", "items": {"type": "string"}, "description": "Key terms (optional)"}
            },
            "required": ["role", "content"]
        }
    },
    "analyze_compression_tool": {
        "function": analyze_compression_tool,
        "description": "Analyze text compression potential with summary generation and technical term extraction",
        "inputSchema": {
            "type": "object",
            "properties": {
                "text": {"type": "string", "description": "Text to analyze for compression potential"}
            },
            "required": ["text"]
        }
    },
    "save_insight_tool": {
        "function": save_insight_tool,
        "description": "Save insights with business impact analysis and actionable items",
        "inputSchema": {
            "type": "object",
            "properties": {
                "insight_type": {"type": "string", "enum": ["solution", "problem", "trend", "opportunity"], "description": "Type of insight"},
                "content": {"type": "string", "description": "Insight content"},
                "summary": {"type": "string", "description": "Brief summary of the insight", "default": ""},
                "source_messages": {"type": "array", "items": {"type": "string"}, "description": "Source message IDs (optional)"},
                "relevance_score": {"type": "number", "minimum": 0, "maximum": 1, "description": "Relevance score (0-1)", "default": 0.8},
                "business_area": {"type": "string", "description": "Business area or domain", "default": ""},
                "impact_level": {"type": "string", "enum": ["low", "medium", "high", "critical"], "description": "Impact level", "default": "medium"},
                "actionable_items": {"type": "array", "items": {"type": "string"}, "description": "List of actionable items (optional)"}
            },
            "required": ["insight_type", "content"]
        }
    }
}

# === MCP MESSAGE HANDLER ===

class MCPMessageHandler:
    """å¤„ç†MCPåè®®æ¶ˆæ¯"""
    
    def __init__(self):
        self.initialized = False
    
    async def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†MCPæ¶ˆæ¯å¹¶è¿”å›å“åº”"""
        method = message.get("method")
        params = message.get("params", {})
        msg_id = message.get("id")
        
        logger.info(f"Processing MCP method: {method}")
        
        try:
            if method == "initialize":
                return await self._handle_initialize(msg_id, params)
            elif method == "notifications/initialized":
                return await self._handle_initialized_notification(msg_id, params)
            elif method == "tools/list":
                return await self._handle_tools_list(msg_id)
            elif method == "tools/call":
                return await self._handle_tools_call(msg_id, params)
            else:
                return {
                    "jsonrpc": "2.0",
                    "id": msg_id,
                    "error": {
                        "code": -32601,
                        "message": f"Unknown method: {method}"
                    }
                }
        except Exception as e:
            logger.error(f"Error handling MCP message: {e}")
            return {
                "jsonrpc": "2.0",
                "id": msg_id,
                "error": {
                    "code": -32603,
                    "message": f"Internal error: {str(e)}"
                }
            }
    
    async def _handle_initialize(self, msg_id: Any, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åˆå§‹åŒ–è¯·æ±‚"""
        self.initialized = True
        logger.info(f"MCP Server initialized with params: {params}")
        
        return {
            "jsonrpc": "2.0",
            "id": msg_id,
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "tools": {"listChanged": True},
                    "prompts": {"listChanged": False},
                    "resources": {"subscribe": False, "listChanged": False}
                },
                "serverInfo": {
                    "name": "Enhanced Conversation System MCP Server",
                    "version": "2.0.0"
                }
            }
        }
    
    async def _handle_initialized_notification(self, msg_id: Any, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åˆå§‹åŒ–å®Œæˆé€šçŸ¥"""
        logger.info(f"Client initialization completed with params: {params}")
        
        # For notifications, we don't need to return a response with an id
        # But we'll return a success response anyway for compatibility
        return {
            "jsonrpc": "2.0",
            "result": "ok"
        }
    
    async def _handle_tools_list(self, msg_id: Any) -> Dict[str, Any]:
        """å¤„ç†å·¥å…·åˆ—è¡¨è¯·æ±‚"""
        tools = []
        for tool_name, tool_config in MCP_TOOLS.items():
            tools.append({
                "name": tool_name,
                "description": tool_config["description"],
                "inputSchema": tool_config["inputSchema"]
            })
        
        return {
            "jsonrpc": "2.0",
            "id": msg_id,
            "result": {"tools": tools}
        }
    
    async def _handle_tools_call(self, msg_id: Any, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        if tool_name not in MCP_TOOLS:
            return {
                "jsonrpc": "2.0",
                "id": msg_id,
                "error": {
                    "code": -32602,
                    "message": f"Unknown tool: {tool_name}"
                }
            }
        
        tool_config = MCP_TOOLS[tool_name]
        tool_function = tool_config["function"]
        
        logger.info(f"Executing tool: {tool_name} with args: {arguments}")
        
        try:
            result = await tool_function(**arguments)
            
            return {
                "jsonrpc": "2.0",
                "id": msg_id,
                "result": {
                    "content": [
                        {
                            "type": "text",
                            "text": result
                        }
                    ]
                }
            }
        except Exception as e:
            logger.error(f"Tool execution error: {e}")
            return {
                "jsonrpc": "2.0",
                "id": msg_id,
                "error": {
                    "code": -32603,
                    "message": f"Tool execution failed: {str(e)}"
                }
            }

# Global message handler
message_handler = MCPMessageHandler()

# === FASTAPI APP WITH SSE ===

app = FastAPI(title="Enhanced Conversation System MCP Server", version="2.0.0")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === SSE ENDPOINT ===

@app.get("/sse")
@app.post("/sse")
@app.options("/sse")
async def sse_endpoint(request: Request):
    """SSEç«¯ç‚¹ - MCP over Server-Sent Eventsï¼Œæ”¯æŒGETã€POSTå’ŒOPTIONS"""
    
    # Handle OPTIONS request for CORS preflight
    if request.method == "OPTIONS":
        return JSONResponse(
            content={},
            headers={
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "Access-Control-Allow-Methods": "GET, POST, OPTIONS"
            }
        )
    
    # For Cursor and other MCP clients, we need to handle both GET and POST
    if request.method == "POST":
        # Handle POST request for immediate message processing
        try:
            body = await request.json()
            logger.info(f"SSE POST request with body: {body}")
            
            # Process the message immediately for POST requests
            response = await message_handler.handle_message(body)
            return JSONResponse(content=response)
            
        except Exception as e:
            logger.error(f"Error processing SSE POST: {e}")
            return JSONResponse(content={
                "jsonrpc": "2.0",
                "error": {
                    "code": -32600,
                    "message": f"Invalid request: {str(e)}"
                }
            }, status_code=400)
    
    # Handle GET request for SSE stream
    async def event_stream():
        logger.info("SSE connection established")
        
        try:
            # Send initial connection confirmation
            yield f"event: connected\n"
            yield f"data: {json.dumps({'type': 'connected', 'timestamp': datetime.now().isoformat()})}\n\n"
            
            # Keep connection alive with periodic pings
            while True:
                await asyncio.sleep(30)
                # Send keepalive ping
                yield f"event: ping\n"
                yield f"data: {json.dumps({'type': 'ping', 'timestamp': datetime.now().isoformat()})}\n\n"
                
        except asyncio.CancelledError:
            logger.info("SSE connection closed")
        except Exception as e:
            logger.error(f"SSE stream error: {e}")
    
    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS"
        }
    )

# === MESSAGE ENDPOINT ===

class MCPMessage(BaseModel):
    jsonrpc: str = "2.0"
    method: str
    params: Optional[Dict[str, Any]] = None
    id: Optional[Any] = None

@app.post("/message")
async def message_endpoint(message: MCPMessage):
    """Messageç«¯ç‚¹ - å¤„ç†MCPè¯·æ±‚å¹¶é€šè¿‡SSEè¿”å›å“åº”"""
    
    logger.info(f"Received MCP message: {message.method}")
    
    # Process the message
    response = await message_handler.handle_message(message.dict())
    
    # Return the response directly (for SSE clients, this gets sent over the SSE connection)
    return JSONResponse(content=response)

# === HEALTH CHECK ===

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # Check API connection
        api_health = await api.health_check()
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "mcp_server": "v2.0.0",
            "transport": "sse",
            "api_backend": api_health,
            "initialized": message_handler.initialized
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# === ROOT ENDPOINT FOR COMPATIBILITY ===

@app.get("/")
async def root():
    """Root endpoint with MCP server information"""
    return {
        "name": "Enhanced Conversation System MCP Server",
        "version": "2.0.0",
        "transport": "sse",
        "endpoints": {
            "sse": "/sse",
            "message": "/message",
            "health": "/health"
        },
        "description": "MCP Server with SSE transport for enhanced conversation management"
    }

if __name__ == "__main__":
    # Configure server parameters
    host = os.getenv("MCP_SERVER_HOST", "0.0.0.0")
    port = int(os.getenv("MCP_SERVER_PORT", "3001"))
    
    logger.info(f"ğŸš€ Starting Enhanced MCP Server v2.0 with SSE Transport...")
    logger.info(f"ğŸŒ Server will listen on {host}:{port}")
    logger.info(f"ğŸ”— API Backend: {api.base_url}")
    logger.info(f"ğŸ“¡ SSE Endpoint: http://{host}:{port}/sse")
    logger.info(f"ğŸ’¬ Message Endpoint: http://{host}:{port}/message")
    
    try:
        uvicorn.run(app, host=host, port=port, log_level="info")
    except Exception as e:
        logger.error(f"Failed to start server: {e}")
        sys.exit(1)
